{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Regression on given dataset",
   "id": "47cb52d53269dfd1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:45.155010Z",
     "start_time": "2025-04-08T14:26:43.344587Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, RobustScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:45.170463Z",
     "start_time": "2025-04-08T14:26:45.167292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_score(y_true, y_pred):\n",
    "    print(f\"Testing model:\\n\", f'\\t-r2: {r2_score(y_true, y_pred)}\\n', f'\\t-MSE: {mean_squared_error(y_true, y_pred)}\\n', f\"\\t-ABSE: {mean_absolute_error(y_true, y_pred)}\\n\")\n"
   ],
   "id": "e1e518e7b6ced5e8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:45.204661Z",
     "start_time": "2025-04-08T14:26:45.175353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = pd.read_csv(\"./data/Xtrain.csv\")\n",
    "X.drop([\"dteday\"], axis=1, inplace=True)\n",
    "y = pd.read_csv(\"./data/ytrain.csv\")\n",
    "y_1 = y.casual.copy()\n",
    "y_2 = y.registered.copy()\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X.values, y_1.values, test_size=0.2, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X.values, y_2.values, test_size=0.2, random_state=42)"
   ],
   "id": "e1ab71b6242ab9ad",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:45.389683Z",
     "start_time": "2025-04-08T14:26:45.370734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X.shape)\n",
    "X.head(2)"
   ],
   "id": "6de7d6e1d1123926",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13034, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   instant  season  yr  mnth  hr  holiday  weekday  workingday  weathersit  \\\n",
       "0        1       1   0     1   0        0        6           0           1   \n",
       "1        2       1   0     1   1        0        6           0           1   \n",
       "\n",
       "   temp   atemp   hum  windspeed  \n",
       "0  0.24  0.2879  0.81        0.0  \n",
       "1  0.22  0.2727  0.80        0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:45.575530Z",
     "start_time": "2025-04-08T14:26:45.570434Z"
    }
   },
   "cell_type": "code",
   "source": "y.head(2)",
   "id": "20a40e02dfaa797c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   casual  registered\n",
       "0       3          13\n",
       "1       8          32"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:45.739905Z",
     "start_time": "2025-04-08T14:26:45.737294Z"
    }
   },
   "cell_type": "code",
   "source": "#sns.pairplot(X, corner=True)",
   "id": "89df922375d2a61b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <span style=\"color:green\"> Lets try boosted trees regressors",
   "id": "886927ec4566bf6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:46.808399Z",
     "start_time": "2025-04-08T14:26:46.044790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X1_train, y1_train)\n",
    "y_pred = model.predict(X1_test)\n",
    "check_score(y1_test, y_pred)"
   ],
   "id": "51cc87900bf1b288",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.9327579140663147\n",
      " \t-MSE: 142.69940185546875\n",
      " \t-ABSE: 7.346523284912109\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:47.876076Z",
     "start_time": "2025-04-08T14:26:46.927116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(X2_train, y2_train)\n",
    "y_pred = model.predict(X2_test)\n",
    "check_score(y2_test, y_pred)"
   ],
   "id": "25569efffb5bf012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.9579663276672363\n",
      " \t-MSE: 695.7962036132812\n",
      " \t-ABSE: 16.672039031982422\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <span style=\"color:green\"> Now a little param tuning",
   "id": "35243bc6d923a8e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:49.118235Z",
     "start_time": "2025-04-08T14:26:47.905528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = XGBRegressor(n_estimators=1000, learning_rate=0.1)\n",
    "model.fit(X1_train, y1_train)\n",
    "y_pred = model.predict(X1_test)\n",
    "check_score(y1_test, y_pred)"
   ],
   "id": "50d5dd25d569172e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.9372549653053284\n",
      " \t-MSE: 133.15577697753906\n",
      " \t-ABSE: 7.128956317901611\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:50.179539Z",
     "start_time": "2025-04-08T14:26:49.144025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = XGBRegressor(n_estimators=1000, learning_rate=0.1)\n",
    "model.fit(X2_train, y2_train)\n",
    "y_pred = model.predict(X2_test)\n",
    "check_score(y2_test, y_pred)"
   ],
   "id": "65cdf9e690bcd279",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.9608710408210754\n",
      " \t-MSE: 647.71337890625\n",
      " \t-ABSE: 15.734640121459961\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> sligtly better",
   "id": "f352b295b8f89afc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest regressor",
   "id": "bec9963c44008391"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:52.257655Z",
     "start_time": "2025-04-08T14:26:50.201631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = XGBRFRegressor(n_estimators=2000)\n",
    "model.fit(X1_train, y1_train)\n",
    "y_pred = model.predict(X1_test)\n",
    "check_score(y1_test, y_pred)"
   ],
   "id": "406a9d1353ed0be1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.8202438354492188\n",
      " \t-MSE: 381.4737548828125\n",
      " \t-ABSE: 11.14776611328125\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:26:53.362566Z",
     "start_time": "2025-04-08T14:26:52.299847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = XGBRFRegressor(n_estimators=1000)\n",
    "model.fit(X2_train, y2_train)\n",
    "y_pred = model.predict(X2_test)\n",
    "check_score(y2_test, y_pred)"
   ],
   "id": "fbe1571accd9a61a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.763891339302063\n",
      " \t-MSE: 3908.3759765625\n",
      " \t-ABSE: 41.3068733215332\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Maybe some neural networks??",
   "id": "1dce16039c2afa0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:27:02.862724Z",
     "start_time": "2025-04-08T14:26:53.391259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(80,80,80), activation=\"tanh\", solver='adam', max_iter=50, batch_size=5)\n",
    "model.fit(X1_train, y1_train)\n",
    "y_pred = model.predict(X1_test)\n",
    "check_score(y1_test, y_pred)"
   ],
   "id": "7b26a0b855dc59c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: -6.354360933458203e-05\n",
      " \t-MSE: 2122.307900608883\n",
      " \t-ABSE: 31.75054389614632\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lets scale the data and use trees again",
   "id": "667686d107a73cd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:27:02.982021Z",
     "start_time": "2025-04-08T14:27:02.934562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scale_data_row(X):\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])\n",
    "    x_out = pipe.fit_transform(X.T).T\n",
    "    return x_out"
   ],
   "id": "e8b8ecba264756a5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:27:03.042180Z",
     "start_time": "2025-04-08T14:27:03.028214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X1_train_s = scale_data_row(X1_train)\n",
    "X1_test_s = scale_data_row(X1_test)\n",
    "X2_train_s = scale_data_row(X2_train)\n",
    "X2_test_s = scale_data_row(X2_test)"
   ],
   "id": "a094c38b242d8b5c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:27:04.831101Z",
     "start_time": "2025-04-08T14:27:03.066202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = XGBRegressor(n_estimators=1000, learning_rate=0.1)\n",
    "model.fit(X1_train_s, y1_train)\n",
    "y_pred = model.predict(X1_test_s)\n",
    "check_score(y1_test, y_pred)"
   ],
   "id": "e6f8dabc0222de08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.853745698928833\n",
      " \t-MSE: 310.3769226074219\n",
      " \t-ABSE: 10.469403266906738\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:27:06.611630Z",
     "start_time": "2025-04-08T14:27:04.855739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.fit(X2_train_s, y2_train)\n",
    "y_pred = model.predict(X2_test_s)\n",
    "check_score(y2_test, y_pred)"
   ],
   "id": "8630597510d1eec6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.8185337781906128\n",
      " \t-MSE: 3003.86376953125\n",
      " \t-ABSE: 36.280235290527344\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> nope, bad idea, i think scaling with trees dont go along(if i remember correctly, trees are not vurnable for scaling in data)",
   "id": "26ad6ccd3c278e0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Maybe simple linear regression will work?",
   "id": "cda452f962ed1046"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:27:06.670733Z",
     "start_time": "2025-04-08T14:27:06.655140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X1_train, y1_train)\n",
    "y_pred = model.predict(X1_test)\n",
    "check_score(y1_test, y_pred)"
   ],
   "id": "b804e8125c8d2fed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.4591027157842643\n",
      " \t-MSE: 1147.8776394206611\n",
      " \t-ABSE: 22.925436026206864\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:27:23.782725Z",
     "start_time": "2025-04-08T14:27:06.798382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "degrees = 5\n",
    "\n",
    "for deg in range(1,degrees):\n",
    "    pipeline = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=deg)),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X1_train, y1_train)\n",
    "\n",
    "    y_pred = pipeline.predict(X1_test)\n",
    "    print(f\"Degree:{deg}\")\n",
    "    check_score(y1_test, y_pred)"
   ],
   "id": "fccb777801afaeec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree:1\n",
      "Testing model:\n",
      " \t-r2: 0.4591027157842634\n",
      " \t-MSE: 1147.877639420663\n",
      " \t-ABSE: 22.92543602620693\n",
      "\n",
      "Degree:2\n",
      "Testing model:\n",
      " \t-r2: 0.6396706217017906\n",
      " \t-MSE: 764.6812957742528\n",
      " \t-ABSE: 18.41852643124198\n",
      "\n",
      "Degree:3\n",
      "Testing model:\n",
      " \t-r2: 0.7136988712721845\n",
      " \t-MSE: 607.5805395918368\n",
      " \t-ABSE: 16.505627588420165\n",
      "\n",
      "Degree:4\n",
      "Testing model:\n",
      " \t-r2: 0.6824320391076881\n",
      " \t-MSE: 673.9341681725068\n",
      " \t-ABSE: 17.260104906130508\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> Not bad, but we can see overtraining later, but still 0.71 r2, and nice Absolute error, seems ok, neural network should work fine then but its for sure overtrain",
   "id": "39a09068f4297863"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:27:36.246985Z",
     "start_time": "2025-04-08T14:27:23.812119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "degrees = 5\n",
    "\n",
    "for deg in range(1,degrees):\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=deg)),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X1_train, y1_train)\n",
    "\n",
    "    y_pred = pipeline.predict(X1_test)\n",
    "    print(f\"Degree:{deg}\")\n",
    "    check_score(y1_test, y_pred)"
   ],
   "id": "c3f3cb379dfaece5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree:1\n",
      "Testing model:\n",
      " \t-r2: 0.4591027157842632\n",
      " \t-MSE: 1147.8776394206634\n",
      " \t-ABSE: 22.92543602620697\n",
      "\n",
      "Degree:2\n",
      "Testing model:\n",
      " \t-r2: 0.6396706203056758\n",
      " \t-MSE: 764.6812987370499\n",
      " \t-ABSE: 18.418526449626658\n",
      "\n",
      "Degree:3\n",
      "Testing model:\n",
      " \t-r2: 0.7896455144635877\n",
      " \t-MSE: 446.4086201674814\n",
      " \t-ABSE: 14.319722865546298\n",
      "\n",
      "Degree:4\n",
      "Testing model:\n",
      " \t-r2: -22242.55880631237\n",
      " \t-MSE: 47204681.03648449\n",
      " \t-ABSE: 249.45104834107022\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> with scaler even better results",
   "id": "3da03eb675fc9ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVR??",
   "id": "c04e24226d93013d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:27:41.232462Z",
     "start_time": "2025-04-08T14:27:36.322737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SVR(kernel='rbf', degree=4,epsilon=0.01) # rbf kernel, eps = 0.1\n",
    "model.fit(X1_train, y1_train)\n",
    "y_pred = model.predict(X1_test)\n",
    "check_score(y1_test, y_pred)"
   ],
   "id": "26f4f63066301bf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: -0.01555793397622085\n",
      " \t-MSE: 2155.1896782728095\n",
      " \t-ABSE: 25.902865798879013\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> but we know SVM doesnt like non scaled data, so lets try scale a little bit and play with different kind of transformations",
   "id": "beb7b7a5af1d6eaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:28:07.458117Z",
     "start_time": "2025-04-08T14:27:41.240594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', SVR(kernel='rbf'))\n",
    "])\n",
    "\n",
    "pipeline.fit(X1_train, y1_train)\n",
    "\n",
    "y_pred = pipeline.predict(X1_test)\n",
    "print(\"SVR-rbf, standarded scaled:\")\n",
    "check_score(y1_test, y_pred)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('regressor', SVR(kernel='rbf'))\n",
    "])\n",
    "\n",
    "pipeline.fit(X1_train, y1_train)\n",
    "\n",
    "y_pred = pipeline.predict(X1_test)\n",
    "print(\"SVR-rbf, robust scaled:\")\n",
    "check_score(y1_test, y_pred)\n",
    "\n",
    "degrees = 6\n",
    "for deg in range(1,degrees):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('regressor', SVR(kernel='poly',degree=deg,epsilon=0.1))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X1_train, y1_train)\n",
    "\n",
    "    y_pred = pipeline.predict(X1_test)\n",
    "    print(f\"SVR-poly{deg}, standarded scaled:\")\n",
    "    check_score(y1_test, y_pred)\n"
   ],
   "id": "9297c1d912786513",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR-rbf, standarded scaled:\n",
      "Testing model:\n",
      " \t-r2: 0.5276974161081092\n",
      " \t-MSE: 1002.3078150155193\n",
      " \t-ABSE: 16.137221281004557\n",
      "\n",
      "SVR-rbf, robust scaled:\n",
      "Testing model:\n",
      " \t-r2: 0.5384129719211853\n",
      " \t-MSE: 979.5675512524491\n",
      " \t-ABSE: 15.98917765010838\n",
      "\n",
      "SVR-poly1, standarded scaled:\n",
      "Testing model:\n",
      " \t-r2: 0.32526879676975873\n",
      " \t-MSE: 1431.896375538984\n",
      " \t-ABSE: 20.701716838883893\n",
      "\n",
      "SVR-poly2, standarded scaled:\n",
      "Testing model:\n",
      " \t-r2: 0.5208646529025067\n",
      " \t-MSE: 1016.8081209479839\n",
      " \t-ABSE: 17.476607934771867\n",
      "\n",
      "SVR-poly3, standarded scaled:\n",
      "Testing model:\n",
      " \t-r2: 0.507665485310903\n",
      " \t-MSE: 1044.8190386942906\n",
      " \t-ABSE: 17.69653626137258\n",
      "\n",
      "SVR-poly4, standarded scaled:\n",
      "Testing model:\n",
      " \t-r2: 0.49332670217662977\n",
      " \t-MSE: 1075.2484178326958\n",
      " \t-ABSE: 17.839760493486427\n",
      "\n",
      "SVR-poly5, standarded scaled:\n",
      "Testing model:\n",
      " \t-r2: 0.44613954200306305\n",
      " \t-MSE: 1175.3877374625479\n",
      " \t-ABSE: 18.76410091576881\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> scaling is all you need somethimes(expecially in SVM, where you base on vectors reliationship). So the final best model is xgboost trees regressors working very well for this kind of data.",
   "id": "e004599d0f7a8f9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# <span style=\"color:lightgreen;\">First tree tuning",
   "id": "3887a6e68f567ea6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T14:29:17.885843Z",
     "start_time": "2025-04-08T14:29:16.665276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = XGBRegressor(n_estimators=1000, learning_rate=0.09)\n",
    "model.fit(X1_train, y1_train)\n",
    "y_pred = model.predict(X1_test)\n",
    "check_score(y1_test, y_pred)"
   ],
   "id": "d8e24941f7fae185",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model:\n",
      " \t-r2: 0.9381145238876343\n",
      " \t-MSE: 131.33175659179688\n",
      " \t-ABSE: 7.101688385009766\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
